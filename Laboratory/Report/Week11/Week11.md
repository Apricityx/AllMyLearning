# 注意力机制

（Attention Mechanism）是深度学习中一种关键技术，灵感来源于人类在处理信息时的选择性关注能力。它使得模型能够在处理输入数据时，动态地调整其注意力权重，从而突出重要信息并忽略不重要的信息 。

例如，某一个词mole有多个意思，Transformer模型会根据上下文来判断这个词的意思。

## 单头注意力机制

将所有的嵌入向量乘以查询矩阵，获得一个查询向量

将所有的嵌入向量乘以键矩阵，获得一个键向量

键向量和查询向量的点积，得到一个注意力分数矩阵，点积越大，表示这两个词越相关

值矩阵乘以嵌入向量，可以获得一个值向量，该向量类似于一个偏移量，例如

fluffy creature这个词中，flutffy的embedding向量乘以值矩阵，得到一个值向量，将这个值向量和creature的embedding向量相乘就可以得到一个表示fluffy creature的embedding向量

可以理解为值向量代表一个向量的属性，用这个向量乘以任意向量的操作即是给任意向量加上一个属性  